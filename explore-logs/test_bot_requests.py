#!/usr/bin/env python3
"""
test_bot_detection.py
---------------------
Quick check for your `is_bot_request` function against an Nginx/Apache-style
access.log that has the format:

    ip - - [date] "METHOD path HTTP/x" status bytes "referrer" "user-agent" "x-forwarded-for"

Place this script next to `access.log` and run:
    python test_bot_detection.py
"""

import re
from collections import Counter
from pathlib import Path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Your original function (verbatim)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def is_bot_request(request):
    user_agent_string = request.META.get("HTTP_USER_AGENT", "").lower().strip()

    bot_keyword_signatures = [
        # â”€â”€ Generic crawler verbs â”€â”€
        "bot", "crawl", "spider", "slurp", "reader", "fetch",
        "monitor", "analyzer", "healthcheck",

        # â”€â”€ Programming languages / HTTP libraries â”€â”€
        "python", "requests", "urllib", "java",
        "okhttp", "curl", "wget", "libwww",
        "httpclient", "go-http-client", "axios",
        "got", "postman", "insomnia",

        # â”€â”€ Headless browsers / testing tools â”€â”€
        "headlesschrome", "phantomjs", "puppeteer",
        "playwright", "selenium", "chromedp",
        "lighthouse", "pagespeed",

        # â”€â”€ Major search / SEO crawlers (roots without â€œbotâ€) â”€â”€
        "ahrefs", "semrush", "yandex",

        # â”€â”€ AI / LLM harvesters (roots without â€œbotâ€) â”€â”€
        "openai", "chatgpt", "oai-search", "perplexity",
        "googleother", "google-read-aloud",

        # â”€â”€ Social-media link fetchers lacking â€œbotâ€ â”€â”€
        "facebookexternalhit", "embedly", "whatsapp",

        # â”€â”€ Uptime & infrastructure monitors â”€â”€
        "pingdom", "statuscake",

        # â”€â”€ Misc keywords you already use â”€â”€
        "support", "feed", "spreadsheet", "script", "about",
    ]

    # Blank or missing User-Agent almost always means â€œbotâ€.
    if not user_agent_string or user_agent_string == "-":
        return True

    for bot_signature in bot_keyword_signatures:
        if bot_signature in user_agent_string:
            return True

    # Otherwise, looks like a human browser.
    return False


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper: pull the User-Agent out of an access-log line
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
UA_REGEX = re.compile(r'"([^"]*)"')       # grabs everything between quotes

def extract_user_agent(log_line: str) -> str:
    """
    Returns the second-to-last quoted substring, which is the User-Agent
    in the default Nginx/Apache combined log format. Returns an empty
    string if it cannot be found.
    """
    quoted_parts = UA_REGEX.findall(log_line)
    if len(quoted_parts) >= 2:
        return quoted_parts[-2]
    return ""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Minimal Request object stand-in
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class DummyRequest:
    """
    Mimics Django/DRF's request just enough for is_bot_request:
    - Holds a META dict with "HTTP_USER_AGENT".
    """
    __slots__ = ("META",)

    def __init__(self, user_agent: str):
        self.META = {"HTTP_USER_AGENT": user_agent}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main test routine
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    log_path = Path("access.log")
    if not log_path.exists():
        raise SystemExit("âš ï¸  access.log not found in the current directory.")

    human_lines, bot_lines = [], []
    ua_counter = Counter()

    with log_path.open(encoding="utf-8", errors="replace") as fh:
        for line in fh:
            ua = extract_user_agent(line)
            ua_counter[ua] += 1

            dummy_request = DummyRequest(ua)
            if is_bot_request(dummy_request):
                bot_lines.append(line.rstrip())
            else:
                human_lines.append(line.rstrip())

    # â”€â”€ Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total = len(bot_lines) + len(human_lines)
    print(f"\nProcessed {total:,} log lines from {log_path}.\n")
    print(f"ðŸ”  Classified as bots  : {len(bot_lines):>7}")
    print(f"ðŸ‘¤  Classified as humans: {len(human_lines):>7}\n")

    # Show a quick sample (first 5 of each)
    def show_sample(tag: str, lines: list[str]):
        print(f"{tag} (showing up to 5)")
        print("-" * len(tag))
        for line in lines[:5]:
            print(line)
        if len(lines) > 5:
            print(f"... and {len(lines) - 5} more\n")
        else:
            print()

    show_sample("ðŸš¦ Bot-like requests", bot_lines)
    show_sample("âœ… Human-like requests", human_lines)

    # â”€â”€ Top 100 bot UAs only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bot_ua_counter = Counter()
    for line in bot_lines:
        ua = extract_user_agent(line)
        if ua:  # skip blank strings
            bot_ua_counter[ua] += 1

    print("Top 100 Bot User-Agents by frequency")
    print("------------------------------------")
    for ua, count in bot_ua_counter.most_common(100):
        print(f"{count:>6} Ã— {ua}")


    # â”€â”€ Top 100 Human UAs only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    human_ua_counter = Counter()
    for line in human_lines:
        ua = extract_user_agent(line)
        if ua:  # skip blank strings
            human_ua_counter[ua] += 1

    print("Top 100 Human User-Agents by frequency")
    print("---------------------------------------")
    for ua, count in human_ua_counter.most_common(100):
        print(f"{count:>6} Ã— {ua}")


if __name__ == "__main__":
    main()
